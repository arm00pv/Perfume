<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live Perfume Identifier</title>
    <style>
        body {
            font-family: sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            margin-top: 20px;
            background-color: #f0f0f0;
        }
        h1 {
            color: #333;
        }
        #container {
            position: relative;
            width: 640px;
            height: 480px;
            border: 2px solid black;
        }
        #video, #overlay-canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        #overlay-canvas {
            cursor: pointer;
        }
    </style>
</head>
<body>
    <h1>Live Perfume Identifier</h1>
    <p>Point your camera at a perfume bottle.</p>
    <div id="container">
        <video id="video" autoplay playsinline></video>
        <canvas id="overlay-canvas"></canvas>
    </div>
    <div id="status"></div>

    <script>
        const video = document.getElementById('video');
        const overlayCanvas = document.getElementById('overlay-canvas');
        const overlayCtx = overlayCanvas.getContext('2d');
        const statusDiv = document.getElementById('status');

        let lastDetections = [];
        let isRequesting = false;
        const processInterval = 1000; // ms between requests

        async function startCamera() {
            try {
                const constraints = { video: { facingMode: 'environment' } };
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                video.addEventListener('loadedmetadata', () => {
                    overlayCanvas.width = video.videoWidth;
                    overlayCanvas.height = video.videoHeight;
                    // Start the processing loop
                    setInterval(processFrame, processInterval);
                });
            } catch (err) {
                console.error("Error accessing camera: ", err);
                alert("Could not access the camera. Please make sure you have a camera connected and have granted permission.");
            }
        }

        async function processFrame() {
            if (isRequesting || video.paused || video.ended) {
                return;
            }
            isRequesting = true;
            statusDiv.textContent = 'Analyzing...';

            // Draw current video frame to a temporary canvas to get data URL
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = video.videoWidth;
            tempCanvas.height = video.videoHeight;
            const tempCtx = tempCanvas.getContext('2d');
            tempCtx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);
            const dataUrl = tempCanvas.toDataURL('image/jpeg');

            try {
                const response = await fetch('https://perfume-dj64.onrender.com/api/identify', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ image: dataUrl }),
                });

                if (!response.ok) {
                    // If we get an error response, try to parse the JSON body for a specific error message
                    const errorData = await response.json();
                    throw new Error(errorData.error || `HTTP error! status: ${response.status}`);
                }

                const data = await response.json();
                handleDetections(data);

            } catch (error) {
                console.error('Error identifying perfume:', error);
                statusDiv.textContent = `Error: ${error.message}`;
                // Clear old overlays on error
                overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
                lastDetections = [];
            } finally {
                isRequesting = false;
            }
        }

        function handleDetections(data) {
            statusDiv.textContent = 'Live'; // Update status now that request is complete
            lastDetections = data.raw_prediction ? data.raw_prediction.predictions : [];
            drawOverlays();
        }

        function drawOverlays() {
            overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);

            lastDetections.forEach(p => {
                // Draw bounding box
                const x = p.x - p.width / 2;
                const y = p.y - p.height / 2;
                overlayCtx.strokeStyle = '#00FF00';
                overlayCtx.lineWidth = 4;
                overlayCtx.strokeRect(x, y, p.width, p.height);

                // Draw label
                overlayCtx.fillStyle = '#00FF00';
                overlayCtx.font = '24px Arial';
                const label = `${p.class} (${(p.confidence * 100).toFixed(1)}%)`;
                overlayCtx.fillText(label, x, y > 30 ? y - 10 : y + p.height + 30);
            });
        }

        overlayCanvas.addEventListener('click', (event) => {
            const rect = overlayCanvas.getBoundingClientRect();
            const scaleX = overlayCanvas.width / rect.width;
            const scaleY = overlayCanvas.height / rect.height;
            const x = (event.clientX - rect.left) * scaleX;
            const y = (event.clientY - rect.top) * scaleY;

            // Find if a detection was clicked
            const clickedDetection = lastDetections.find(p => {
                const boxX = p.x - p.width / 2;
                const boxY = p.y - p.height / 2;
                return x >= boxX && x <= boxX + p.width && y >= boxY && y <= boxY + p.height;
            });

            if (clickedDetection) {
                statusDiv.textContent = `Clicked on ${clickedDetection.class}. Fetching URL...`;
                // To get the URL, we would need to associate it with the prediction.
                // For now, we'll just re-run a single identification to get the URL.
                // A better implementation would cache URLs or have the backend return all URLs for all detections.
                const tempCanvas = document.createElement('canvas');
                tempCanvas.width = video.videoWidth;
                tempCanvas.height = video.videoHeight;
                const tempCtx = tempCanvas.getContext('2d');
                tempCtx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);
                const dataUrl = tempCanvas.toDataURL('image/jpeg');

                fetch('https://perfume-dj64.onrender.com/api/identify', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ image: dataUrl }),
                })
                .then(res => res.json())
                .then(data => {
                    if(data.fragrantica_url) {
                        window.open(data.fragrantica_url, '_blank');
                    } else {
                        statusDiv.textContent = "Could not find a profile page for the clicked perfume.";
                    }
                });
            }
        });

        startCamera();
    </script>
</body>
</html>
