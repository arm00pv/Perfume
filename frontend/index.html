<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live Perfume Identifier</title>
    <style>
        body {
            font-family: sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            margin-top: 20px;
            background-color: #f0f0f0;
        }
        h1 {
            color: #333;
        }
        #container {
            position: relative;
            width: 640px;
            height: 480px;
            border: 2px solid black;
        }
        #video, #overlay-canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        #overlay-canvas {
            cursor: pointer;
        }
        #results {
            width: 640px;
            margin-top: 20px;
        }
    </style>
</head>
<body>
    <h1>Live Perfume Identifier</h1>
    <p>Point your camera at perfume bottles.</p>
    <div id="container">
        <video id="video" autoplay playsinline></video>
        <canvas id="overlay-canvas"></canvas>
    </div>
    <div id="status"></div>
    <div id="results"></div>

    <script>
        const video = document.getElementById('video');
        const overlayCanvas = document.getElementById('overlay-canvas');
        const overlayCtx = overlayCanvas.getContext('2d');
        const statusDiv = document.getElementById('status');
        const resultsDiv = document.getElementById('results');

        let activeDetections = []; // Will store a list of full result objects
        let isRequesting = false;
        const processInterval = 1000; // ms between requests

        async function startCamera() {
            try {
                const constraints = { video: { facingMode: 'environment' } };
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                video.addEventListener('loadedmetadata', () => {
                    overlayCanvas.width = video.videoWidth;
                    overlayCanvas.height = video.videoHeight;
                    setInterval(processFrame, processInterval);
                });
            } catch (err) {
                console.error("Error accessing camera: ", err);
                alert("Could not access the camera. Please make sure you have a camera connected and have granted permission.");
            }
        }

        async function processFrame() {
            if (isRequesting || video.paused || video.ended) {
                return;
            }
            isRequesting = true;
            statusDiv.textContent = 'Analyzing...';

            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = video.videoWidth;
            tempCanvas.height = video.videoHeight;
            const tempCtx = tempCanvas.getContext('2d');
            tempCtx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);
            const dataUrl = tempCanvas.toDataURL('image/jpeg');

            try {
                const response = await fetch('https://perfume-dj64.onrender.com/api/identify', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ image: dataUrl }),
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.error || `HTTP error! status: ${response.status}`);
                }

                const data = await response.json();
                handleApiResponse(data);

            } catch (error) {
                console.error('Error identifying perfume:', error);
                statusDiv.textContent = `Error: ${error.message}`;
                activeDetections = [];
                drawOverlays();
            } finally {
                isRequesting = false;
            }
        }

        function handleApiResponse(data) {
            statusDiv.textContent = 'Live';
            activeDetections = data.results || [];
            drawOverlays();
            displayResultsList(activeDetections);
        }

        function drawOverlays() {
            overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);

            activeDetections.forEach(det => {
                const p = det.prediction_data;
                const x = p.x - p.width / 2;
                const y = p.y - p.height / 2;

                // Set color based on verification
                overlayCtx.strokeStyle = det.is_verified ? '#00FF00' : '#FFD700'; // Green for verified, Gold for not
                overlayCtx.fillStyle = overlayCtx.strokeStyle;

                overlayCtx.lineWidth = 4;
                overlayCtx.strokeRect(x, y, p.width, p.height);

                overlayCtx.font = '20px Arial';
                const label = `${p.class} (${(p.confidence * 100).toFixed(0)}%) ${det.is_verified ? '✅' : ''}`;
                overlayCtx.fillText(label, x, y > 30 ? y - 10 : y + p.height + 30);
            });
        }

        function displayResultsList(detections) {
            if (detections.length === 0) {
                resultsDiv.innerHTML = '';
                return;
            }

            let html = '<h3>Detected Perfumes:</h3><ul>';
            detections.forEach(det => {
                html += `<li>
                    <strong>${det.prediction_data.class}</strong>
                    (Confidence: ${(det.prediction_data.confidence * 100).toFixed(0)}%) -
                    Verification: ${det.is_verified ? '<span style="color:green;">✅ Verified</span>' : '<span style="color:red;">❌ Unverified</span>'}
                    <br>
                    <small>OCR Text: <em>"${det.ocr_text}"</em></small>
                </li>`;
            });
            html += '</ul>';
            resultsDiv.innerHTML = html;
        }

        overlayCanvas.addEventListener('click', (event) => {
            const rect = overlayCanvas.getBoundingClientRect();
            const scaleX = overlayCanvas.width / rect.width;
            const scaleY = overlayCanvas.height / rect.height;
            const clickX = (event.clientX - rect.left) * scaleX;
            const clickY = (event.clientY - rect.top) * scaleY;

            const clickedDetection = activeDetections.find(det => {
                const p = det.prediction_data;
                const boxX = p.x - p.width / 2;
                const boxY = p.y - p.height / 2;
                return clickX >= boxX && clickX <= boxX + p.width && clickY >= boxY && clickY <= boxY + p.height;
            });

            if (clickedDetection && clickedDetection.fragrantica_url) {
                window.open(clickedDetection.fragrantica_url, '_blank');
            } else if (clickedDetection) {
                statusDiv.textContent = `Could not find a profile page for ${clickedDetection.prediction_data.class}.`;
            }
        });

        startCamera();
    </script>
</body>
</html>
